# üö® EMERGENCY RESPONSE PROCEDURES - WhatsApp Agent

**Data de Atualiza√ß√£o**: 09 de agosto de 2025  
**Vers√£o**: 1.0  
**Responsabilidade**: Equipe de Opera√ß√µes, DevOps e Ger√™ncia

---

## üìã √çNDICE

- [üî• Classifica√ß√£o de Emerg√™ncias](#-classifica√ß√£o-de-emerg√™ncias)
- [‚ö° A√ß√µes Imediatas por Tipo](#-a√ß√µes-imediatas-por-tipo)
- [üìû Plano de Comunica√ß√£o](#-plano-de-comunica√ß√£o)
- [üõ°Ô∏è Procedures de Containment](#Ô∏è-procedures-de-containment)
- [üîÑ Recovery Procedures](#-recovery-procedures)
- [üìã Checklists de Emerg√™ncia](#-checklists-de-emerg√™ncia)
- [üìä Post-Incident Analysis](#-post-incident-analysis)

---

## üî• CLASSIFICA√á√ÉO DE EMERG√äNCIAS

### SEV-1 (CR√çTICO) - Resposta Imediata (< 5 min)

**Crit√©rios**:
- Sistema completamente indispon√≠vel (>95% usu√°rios afetados)
- Perda de dados cr√≠ticos
- Viola√ß√£o de seguran√ßa confirmada
- Incidente de compliance (LGPD/GDPR)

**A√ß√µes Autom√°ticas**:
- Alertas para toda equipe t√©cnica
- Ativa√ß√£o do war room
- Comunica√ß√£o executiva em 15 min

### SEV-2 (URGENTE) - Resposta R√°pida (< 15 min)

**Crit√©rios**:
- Funcionalidade cr√≠tica afetada (50-95% usu√°rios)
- Performance severamente degradada
- Erro de integra√ß√£o com WhatsApp/Meta
- Falha parcial do sistema

**A√ß√µes Autom√°ticas**:
- Alertas para equipe de plant√£o
- Escala√ß√£o autom√°tica em 30 min se n√£o resolvido

### SEV-3 (MODERADO) - Resposta Normal (< 1 hora)

**Crit√©rios**:
- Funcionalidade menor afetada (<50% usu√°rios)
- Performance degradada mas utiliz√°vel
- Problemas de monitoramento
- Issues n√£o-cr√≠ticos

**A√ß√µes Autom√°ticas**:
- Notifica√ß√£o para operador de plant√£o
- Cria√ß√£o de ticket para acompanhamento

### SEV-4 (BAIXO) - Resposta Planejada (< 24 horas)

**Crit√©rios**:
- Problemas menores ou cosm√©ticos
- Melhorias de performance
- Manuten√ß√£o preventiva
- Documenta√ß√£o

---

## ‚ö° A√á√ïES IMEDIATAS POR TIPO

### üî• SISTEMA COMPLETAMENTE DOWN (SEV-1)

**PRIMEIRA RESPOSTA (0-5 minutos)**:

```bash
# PASSO 1: Verifica√ß√£o R√°pida (1 min)
cd /home/vancim/whats_agent
curl -f http://localhost:8000/health || echo "CONFIRMADO: Sistema DOWN"
docker-compose ps | grep -v "Up" | head -5

# PASSO 2: Restart de Emerg√™ncia (2 min)
docker-compose restart app
sleep 30
curl -f http://localhost:8000/health

# PASSO 3: Se n√£o resolver - Restart Completo (2 min)
if ! curl -f http://localhost:8000/health; then
    docker-compose down
    docker-compose up -d
    echo "RESTART COMPLETO EXECUTADO $(date)"
fi
```

**COMUNICA√á√ÉO IMEDIATA**:
```bash
# Notificar Slack
curl -X POST $SLACK_EMERGENCY_WEBHOOK -d '{
  "text": "üö® SEV-1: Sistema WhatsApp Agent DOWN\nIniciando procedures de emerg√™ncia\nETA: 5-10 minutos"
}'

# Notificar Status Page (se existir)
# curl -X POST $STATUS_PAGE_API -d '{"status":"major_outage","message":"Sistema em manuten√ß√£o de emerg√™ncia"}'
```

**ESCALA√á√ÉO AUTOM√ÅTICA (5 min)**:
- Se sistema n√£o voltar em 5 min ‚Üí Acionar DevOps Engineer
- Se n√£o resolver em 15 min ‚Üí Acionar Tech Lead
- Se n√£o resolver em 30 min ‚Üí Acionar Ger√™ncia

---

### üîí INCIDENTE DE SEGURAN√áA (SEV-1)

**CONTAINMENT IMEDIATO (0-3 minutos)**:

```bash
# PASSO 1: Isolar Sistema Imediatamente
docker-compose down
echo "SISTEMA ISOLADO POR SEGURAN√áA $(date)" >> security_incident.log

# PASSO 2: Preservar Evid√™ncias
cp -r logs/ security_incident_$(date +%Y%m%d_%H%M%S)/
docker-compose logs > security_incident_docker_$(date +%Y%m%d_%H%M%S).log

# PASSO 3: Verificar Comprometimento
find . -name "*.py" -newer logs/app.log -exec ls -la {} \;  # Arquivos modificados recentemente
netstat -tulpn | grep LISTEN  # Portas em listening
```

**COMUNICA√á√ÉO DE SEGURAN√áA**:
```bash
# Notificar Equipe de Seguran√ßa
curl -X POST $SECURITY_TEAM_WEBHOOK -d '{
  "text": "üö® SECURITY INCIDENT: WhatsApp Agent\nSistema ISOLADO preventivamente\nEquipe de seguran√ßa favor verificar imediatamente"
}'

# Notificar Compliance (se aplic√°vel)
# Email autom√°tico para compliance@company.com
```

**AN√ÅLISE FORENSE INICIAL**:
```bash
# Verificar tentativas de acesso
grep -i "401\|403\|unauthorized" logs/security.log | tail -50

# Verificar mudan√ßas de configura√ß√£o
git diff HEAD~5 .env docker-compose.yml

# Verificar processos suspeitos
ps aux | grep -v -E "(docker|python|postgres|redis|nginx)"
```

---

### üíæ PERDA DE DADOS (SEV-1)

**IMMEDIATE DAMAGE ASSESSMENT (0-2 minutos)**:

```bash
# PASSO 1: Parar Escritas Imediatamente
docker-compose stop app  # Para prevenir mais corrup√ß√£o

# PASSO 2: Verificar Integridade do Banco
docker-compose exec postgres psql -U $DB_USER $DB_NAME -c "
SELECT 
  schemaname, 
  tablename, 
  n_tup_ins, 
  n_tup_upd, 
  n_tup_del,
  last_autoanalyze
FROM pg_stat_user_tables 
ORDER BY n_tup_ins DESC;"

# PASSO 3: Verificar Backups Dispon√≠veis
ls -la backups/automatic/ | tail -10
ls -la backups/manual/ | tail -5
```

**RECOVERY IMEDIATO**:
```bash
# OP√á√ÉO 1: Se dados parcialmente corrompidos
./scripts/restore_partial_backup.sh critical_tables_only

# OP√á√ÉO 2: Se perda completa
./scripts/restore_full_backup.sh latest

# OP√á√ÉO 3: Point-in-time recovery (se configurado)
./scripts/restore_pitr.sh "2025-08-09 14:30:00"
```

---

### üåê FALHA DE INTEGRA√á√ÉO WHATSAPP (SEV-2)

**DIAGNOSTIC R√ÅPIDO (0-3 minutos)**:

```bash
# PASSO 1: Testar Conectividade Meta API
curl -H "Authorization: Bearer $META_ACCESS_TOKEN" \
     "https://graph.facebook.com/v17.0/$PHONE_NUMBER_ID"

# PASSO 2: Verificar Webhook Status
curl -X POST http://localhost:8000/webhook \
     -H "Content-Type: application/json" \
     -d '{"object":"whatsapp_business_account","entry":[]}'

# PASSO 3: Verificar Logs de Webhook
grep -i "webhook\|whatsapp" logs/app.log | tail -20
```

**WORKAROUNDS IMEDIATOS**:
```bash
# OP√á√ÉO 1: Switch para Token de Backup (se configurado)
export META_ACCESS_TOKEN=$META_BACKUP_TOKEN
docker-compose restart app

# OP√á√ÉO 2: Ativar Modo Degradado
# Configurar sistema para aceitar mensagens sem processar IA
export FALLBACK_MODE=true
docker-compose restart app

# OP√á√ÉO 3: Redirecionar para Sistema de Backup
# (Se configurado) Alterar webhook URL temporariamente
```

---

### ‚ö° SOBRECARGA DO SISTEMA (SEV-2)

**IMMEDIATE LOAD REDUCTION (0-2 minutos)**:

```bash
# PASSO 1: Ativar Rate Limiting Agressivo
# Editar configura√ß√£o temporariamente
export RATE_LIMIT_PER_MINUTE=10  # Reduzir drasticamente
docker-compose restart app

# PASSO 2: Scale Horizontal (se poss√≠vel)
docker-compose up -d --scale app=3

# PASSO 3: Ativar Circuit Breaker
export CIRCUIT_BREAKER_ENABLED=true
export CIRCUIT_BREAKER_THRESHOLD=50
docker-compose restart app
```

**MONITORING INTENSIVO**:
```bash
# Monitor CPU e Memory em tempo real
watch -n 5 'docker stats --no-stream'

# Monitor response times
watch -n 10 'curl -s http://localhost:8000/production/metrics/performance | jq .sla_metrics.response_time'

# Monitor error rate
watch -n 30 'tail -100 logs/app.log | grep ERROR | wc -l'
```

---

## üìû PLANO DE COMUNICA√á√ÉO

### Canais de Emerg√™ncia

**SLACK CHANNELS**:
- `#emergency-incidents` - Coordena√ß√£o de incidentes
- `#whatsapp-agent-alerts` - Alertas espec√≠ficos do sistema
- `#ops-team` - Equipe operacional
- `#dev-team` - Equipe de desenvolvimento

**TELEFONES DE EMERG√äNCIA**:
- **Operador de Plant√£o**: `+55 11 99999-0001`
- **DevOps Engineer**: `+55 11 99999-0002`
- **Tech Lead**: `+55 11 99999-0003`
- **CTO**: `+55 11 99999-0004`

**EMAIL GROUPS**:
- `emergency@company.com` - Toda equipe t√©cnica
- `incidents@company.com` - Equipe de resposta a incidentes
- `executives@company.com` - Lideran√ßa (apenas SEV-1)

### Templates de Comunica√ß√£o

**TEMPLATE: INITIAL INCIDENT NOTIFICATION**
```
üö® INCIDENT ALERT - SEV-[1/2/3]

SYSTEM: WhatsApp Agent
STATUS: [INVESTIGATING/IDENTIFIED/MONITORING/RESOLVED]
IMPACT: [Descrever impacto nos usu√°rios]
START TIME: [YYYY-MM-DD HH:MM UTC]
ETA: [Estimativa de resolu√ß√£o]

INITIAL ACTIONS TAKEN:
- [A√ß√£o 1]
- [A√ß√£o 2]

NEXT STEPS:
- [Pr√≥ximo passo 1]
- [Pr√≥ximo passo 2]

RESPONSIBLE: [Nome do respons√°vel]
INCIDENT COMMANDER: [Nome]

Updates will be provided every [15/30/60] minutes.
```

**TEMPLATE: STATUS UPDATE**
```
üìã INCIDENT UPDATE - SEV-[1/2/3]

SYSTEM: WhatsApp Agent
STATUS: [UPDATE FROM PREVIOUS]
TIME: [Current timestamp]

PROGRESS UPDATE:
- [Progresso desde √∫ltimo update]
- [A√ß√µes completadas]
- [Resultados observados]

CURRENT ACTIONS:
- [O que est√° sendo feito agora]

NEXT UPDATE: [Timestamp do pr√≥ximo update]
ETA: [Updated ETA if changed]
```

**TEMPLATE: INCIDENT RESOLVED**
```
‚úÖ INCIDENT RESOLVED - SEV-[1/2/3]

SYSTEM: WhatsApp Agent
STATUS: RESOLVED
RESOLUTION TIME: [YYYY-MM-DD HH:MM UTC]
TOTAL DURATION: [X hours Y minutes]

FINAL RESOLUTION:
- [Como foi resolvido]
- [Verifica√ß√µes realizadas]

IMPACT SUMMARY:
- [Resumo do impacto nos usu√°rios]
- [N√∫mero de usu√°rios afetados]
- [Funcionalidades afetadas]

POST-MORTEM:
- Scheduled for [Date]
- Action items will be tracked in [Tool/Location]

MONITORING:
System will be monitored closely for the next [timeframe].
```

### Escala√ß√£o Autom√°tica

**TEMPO 0 min**: Incidente detectado
- Alertas autom√°ticos para equipe de plant√£o
- Cria√ß√£o de canal #incident-YYYYMMDD-HHMM

**TEMPO 5 min** (SEV-1) / **15 min** (SEV-2):
- Se n√£o acknowledgment ‚Üí Escala√ß√£o para DevOps
- Notifica√ß√£o para Tech Lead

**TEMPO 15 min** (SEV-1) / **30 min** (SEV-2):
- Se n√£o resolvido ‚Üí Escala√ß√£o para CTO
- Ativa√ß√£o de equipe adicional

**TEMPO 30 min** (SEV-1):
- Se n√£o resolvido ‚Üí Notifica√ß√£o executiva
- Considera√ß√£o de acionamento de vendor support

---

## üõ°Ô∏è PROCEDURES DE CONTAINMENT

### Isolamento de Sistema

**FULL SYSTEM ISOLATION**:
```bash
#!/bin/bash
# emergency_isolation.sh

echo "üö® INICIANDO ISOLAMENTO DE EMERG√äNCIA"
echo "Timestamp: $(date)"

# 1. Parar toda aplica√ß√£o
docker-compose down

# 2. Bloquear tr√°fego externo (se aplic√°vel)
# iptables -A INPUT -p tcp --dport 80 -j DROP
# iptables -A INPUT -p tcp --dport 443 -j DROP

# 3. Preservar estado atual
mkdir -p emergency_$(date +%Y%m%d_%H%M%S)
cp -r logs/ emergency_$(date +%Y%m%d_%H%M%S)/logs/
docker-compose logs > emergency_$(date +%Y%m%d_%H%M%S)/docker_logs.txt

# 4. Notificar isolamento
curl -X POST $SLACK_EMERGENCY_WEBHOOK -d '{
  "text": "üö® SISTEMA ISOLADO - WhatsApp Agent\nTodos os servi√ßos parados preventivamente"
}'

echo "‚úÖ ISOLAMENTO CONCLU√çDO"
```

### Containment por Componente

**ISOLAR APENAS APLICA√á√ÉO**:
```bash
# Manter DB e Redis rodando, parar apenas app
docker-compose stop app nginx
# Manter infraestrutura para an√°lise
```

**ISOLAR APENAS BANCO**:
```bash
# Se suspeita de corrup√ß√£o de dados
docker-compose stop postgres
# Preservar dados para an√°lise forense
```

**MODO SEGURO**:
```bash
# Iniciar sistema em modo somente leitura
export READ_ONLY_MODE=true
export DISABLE_WEBHOOKS=true
docker-compose up -d app
```

---

## üîÑ RECOVERY PROCEDURES

### Recovery Escalonado

**N√çVEL 1 - QUICK RECOVERY**:
```bash
#!/bin/bash
# quick_recovery.sh

echo "‚ö° QUICK RECOVERY PROCEDURE"

# 1. Restart simples
docker-compose restart
sleep 60

# 2. Verifica√ß√£o imediata
if curl -f http://localhost:8000/health; then
    echo "‚úÖ QUICK RECOVERY SUCCESSFUL"
    exit 0
fi

echo "‚ùå QUICK RECOVERY FAILED - Escalando para LEVEL 2"
exit 1
```

**N√çVEL 2 - FULL RESTART**:
```bash
#!/bin/bash
# full_restart_recovery.sh

echo "üîÑ FULL RESTART RECOVERY PROCEDURE"

# 1. Parar tudo
docker-compose down

# 2. Limpeza b√°sica
docker system prune -f

# 3. Reiniciar servi√ßos em ordem
docker-compose up -d postgres redis
sleep 30

docker-compose up -d app
sleep 60

docker-compose up -d nginx dashboard

# 4. Verifica√ß√£o
if curl -f http://localhost:8000/health; then
    echo "‚úÖ FULL RESTART RECOVERY SUCCESSFUL"
    exit 0
fi

echo "‚ùå FULL RESTART FAILED - Escalando para LEVEL 3"
exit 1
```

**N√çVEL 3 - BACKUP RESTORE**:
```bash
#!/bin/bash
# backup_restore_recovery.sh

echo "üíæ BACKUP RESTORE RECOVERY PROCEDURE"

# 1. Parar tudo
docker-compose down

# 2. Restaurar configura√ß√µes
cp backups/automatic/config_$(date +%Y%m%d)*.tar.gz .
tar -xzf config_*.tar.gz

# 3. Restaurar banco de dados
./scripts/restore_backup.sh latest

# 4. Verificar integridade
docker-compose up -d postgres
sleep 30
docker-compose exec postgres psql -U $DB_USER $DB_NAME -c "SELECT count(*) FROM conversations;"

# 5. Reiniciar aplica√ß√£o
docker-compose up -d

# 6. Verifica√ß√£o final
sleep 120
if curl -f http://localhost:8000/health; then
    echo "‚úÖ BACKUP RESTORE RECOVERY SUCCESSFUL"
    exit 0
fi

echo "‚ùå BACKUP RESTORE FAILED - ESCALA√á√ÉO PARA DISASTER RECOVERY"
exit 1
```

### Disaster Recovery

**FULL DISASTER RECOVERY**:
```bash
#!/bin/bash
# disaster_recovery.sh

echo "üÜò DISASTER RECOVERY PROCEDURE"
echo "Iniciando recovery completo em novo ambiente"

# Este script seria executado em uma nova m√°quina/ambiente

# 1. Setup inicial
git clone <repository> whats_agent_recovery
cd whats_agent_recovery

# 2. Restaurar configura√ß√µes cr√≠ticas
# (De backup externo ou reposit√≥rio seguro)
aws s3 cp s3://backup-bucket/configs/ . --recursive

# 3. Restaurar dados
aws s3 cp s3://backup-bucket/database/latest.sql.gz .
gunzip latest.sql.gz

# 4. Setup completo
docker-compose up -d postgres redis
sleep 60
docker-compose exec -T postgres psql -U $DB_USER $DB_NAME < latest.sql

# 5. Iniciar aplica√ß√£o
docker-compose up -d

# 6. Verifica√ß√£o e switchover
# (Atualizar DNS, load balancer, etc.)

echo "üÜò DISASTER RECOVERY COMPLETED"
echo "Verificar funcionamento antes de direcionar tr√°fego"
```

---

## üìã CHECKLISTS DE EMERG√äNCIA

### ‚úÖ CHECKLIST: INCIDENT RESPONSE (SEV-1)

**IMMEDIATE (0-5 minutes)**:
- [ ] Confirm incident severity
- [ ] Start incident war room
- [ ] Execute immediate containment
- [ ] Send initial notification
- [ ] Assign incident commander

**SHORT TERM (5-30 minutes)**:
- [ ] Complete impact assessment
- [ ] Execute recovery procedures
- [ ] Provide regular status updates
- [ ] Escalate if not resolving
- [ ] Document all actions taken

**RESOLUTION**:
- [ ] Confirm system fully operational
- [ ] Run validation tests
- [ ] Send resolution notification
- [ ] Schedule post-mortem
- [ ] Update documentation

### ‚úÖ CHECKLIST: SECURITY INCIDENT

**IMMEDIATE**:
- [ ] Isolate affected systems
- [ ] Preserve evidence
- [ ] Notify security team
- [ ] Document initial findings
- [ ] Assess breach scope

**INVESTIGATION**:
- [ ] Perform forensic analysis
- [ ] Identify attack vectors
- [ ] Assess data compromise
- [ ] Coordinate with authorities (if needed)
- [ ] Prepare legal notifications

**RECOVERY**:
- [ ] Patch vulnerabilities
- [ ] Rotate compromised credentials
- [ ] Restore from clean backups
- [ ] Implement additional controls
- [ ] Monitor for reoccurrence

### ‚úÖ CHECKLIST: DATA LOSS INCIDENT

**IMMEDIATE**:
- [ ] Stop all write operations
- [ ] Assess extent of data loss
- [ ] Identify last good backup
- [ ] Notify stakeholders
- [ ] Preserve corrupted data for analysis

**RECOVERY**:
- [ ] Execute backup restore
- [ ] Validate data integrity
- [ ] Test application functionality
- [ ] Communicate data recovery status
- [ ] Implement additional backup measures

---

## üìä POST-INCIDENT ANALYSIS

### Immediate Post-Incident (Within 24 hours)

**INCIDENT SUMMARY TEMPLATE**:
```markdown
# INCIDENT POST-MORTEM: [INCIDENT-ID]

## Incident Summary
- **Date**: [YYYY-MM-DD]
- **Duration**: [Start] - [End] ([X hours Y minutes])
- **Severity**: SEV-[1/2/3]
- **Impact**: [Description of user impact]
- **Root Cause**: [Brief description]

## Timeline
| Time | Event | Action Taken | Result |
|------|-------|--------------|--------|
| HH:MM | Incident started | - | System down |
| HH:MM | Detection | Automatic alert | Team notified |
| HH:MM | Response started | [Action] | [Result] |
| HH:MM | Resolution | [Final action] | System restored |

## Root Cause Analysis
**What happened**: [Detailed description]
**Why it happened**: [Technical root cause]
**Why it wasn't detected earlier**: [Detection gaps]

## What Went Well
- [Positive aspect 1]
- [Positive aspect 2]

## What Could Be Improved
- [Improvement area 1]
- [Improvement area 2]

## Action Items
| Action | Owner | Due Date | Priority |
|--------|-------|----------|----------|
| [Action 1] | [Name] | [Date] | High |
| [Action 2] | [Name] | [Date] | Medium |

## Lessons Learned
- [Lesson 1]
- [Lesson 2]
```

### Follow-up Actions

**IMMEDIATE (24-48 hours)**:
- [ ] Complete post-mortem document
- [ ] Share with stakeholders
- [ ] Create action item tickets
- [ ] Update emergency procedures

**SHORT TERM (1-2 weeks)**:
- [ ] Implement high-priority fixes
- [ ] Update monitoring/alerting
- [ ] Conduct tabletop exercises
- [ ] Train team on lessons learned

**LONG TERM (1 month+)**:
- [ ] Complete all action items
- [ ] Review incident trends
- [ ] Update architecture (if needed)
- [ ] Conduct emergency drill

### Incident Metrics Tracking

**KPIs to Track**:
- **MTTD** (Mean Time To Detection)
- **MTTR** (Mean Time To Resolution)
- **MTBF** (Mean Time Between Failures)
- **Incident Count** (by severity)
- **Customer Impact** (users affected, revenue impact)

**Monthly Incident Review**:
```bash
# Generate incident report
./scripts/generate_incident_report.sh $(date +%Y-%m)

# Analyze trends
grep "SEV-" incident_log.txt | awk '{print $1}' | sort | uniq -c

# Review action item completion
./scripts/review_action_items.sh
```

---

## üéØ EMERGENCY CONTACT MATRIX

| Role | Primary | Secondary | Escalation Time |
|------|---------|-----------|-----------------|
| **Incident Commander** | DevOps Lead | Tech Lead | Immediate |
| **Technical SME** | Senior Developer | Platform Engineer | 15 min |
| **Communications** | Engineering Manager | Product Manager | 30 min |
| **Executive** | CTO | CEO | 60 min (SEV-1 only) |
| **Legal/Compliance** | Legal Counsel | Compliance Officer | 2 hours (if needed) |

## üì± EMERGENCY AUTOMATION

### Automated Emergency Scripts

**AUTO-RESTART ON CRITICAL FAILURE**:
```bash
#!/bin/bash
# auto_emergency_restart.sh
# Triggered by monitoring system

FAILURE_COUNT_FILE="/tmp/failure_count"
MAX_FAILURES=3

# Increment failure count
if [ -f "$FAILURE_COUNT_FILE" ]; then
    count=$(cat "$FAILURE_COUNT_FILE")
    count=$((count + 1))
else
    count=1
fi

echo $count > "$FAILURE_COUNT_FILE"

if [ $count -le $MAX_FAILURES ]; then
    echo "Auto-restart attempt $count/$MAX_FAILURES"
    docker-compose restart app
    
    # Reset count if successful
    sleep 60
    if curl -f http://localhost:8000/health; then
        rm -f "$FAILURE_COUNT_FILE"
        echo "Auto-restart successful"
    fi
else
    echo "Max auto-restart attempts reached. Manual intervention required."
    curl -X POST $SLACK_EMERGENCY_WEBHOOK -d '{
        "text": "üö® AUTO-RESTART FAILED: Max attempts reached. Manual intervention required."
    }'
fi
```

**MONITORING HEALTH CHECK**:
```bash
#!/bin/bash
# continuous_health_monitor.sh
# Run as cron job every minute

HEALTH_URL="http://localhost:8000/health"
FAILURE_THRESHOLD=3
FAILURE_FILE="/tmp/health_failures"

if curl -f "$HEALTH_URL" > /dev/null 2>&1; then
    # Health check passed, reset failure count
    rm -f "$FAILURE_FILE"
else
    # Health check failed
    if [ -f "$FAILURE_FILE" ]; then
        failures=$(cat "$FAILURE_FILE")
        failures=$((failures + 1))
    else
        failures=1
    fi
    
    echo $failures > "$FAILURE_FILE"
    
    if [ $failures -ge $FAILURE_THRESHOLD ]; then
        # Trigger emergency response
        ./emergency_response.sh "health_check_failure"
        rm -f "$FAILURE_FILE"
    fi
fi
```

---

**√öltima Atualiza√ß√£o**: 09/08/2025  
**Pr√≥xima Revis√£o**: 09/09/2025  
**Vers√£o**: 1.0

---

**IMPORTANTE**: Este documento deve ser revisado mensalmente e atualizado ap√≥s cada incidente significativo. Todos os membros da equipe devem estar familiarizados com estes procedimentos.
